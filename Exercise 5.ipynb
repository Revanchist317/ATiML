{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ce6532-22fa-4129-87ea-cd462123e663",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7abdd38-7cfc-4d24-9487-18247c82b504",
   "metadata": {},
   "source": [
    "## Assignment 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3cd99-92d1-4b1c-9bf2-69644efd3d70",
   "metadata": {},
   "source": [
    "Given are the following points A(−0.5;1), B(−1;−1.5), C(−1.5;1.5), D(1.5;−0.5) and E(0.5;−0.5) as shown below. The goal is to learn a decision function $f$ using Linear Learning Machines (LLM) that separates A and E from the other points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f2d6a-ddd3-4adc-bac1-634858b26b5b",
   "metadata": {},
   "source": [
    "<img src=\"5_figure.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb9fae-3ca7-439a-b0ab-6a5e030b23fa",
   "metadata": {},
   "source": [
    "a) Compute the kernel matrix for $K(x_1, x_2) = \\langle x_1, x_2  \\rangle ^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdd3421b-dbe5-492b-8ffe-9d65fe0620fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81, 36,  9,  0,  9, 36, 81],\n",
       "       [36, 16,  4,  0,  4, 16, 36],\n",
       "       [ 9,  4,  1,  0,  1,  4,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 9,  4,  1,  0,  1,  4,  9],\n",
       "       [36, 16,  4,  0,  4, 16, 36],\n",
       "       [81, 36,  9,  0,  9, 36, 81]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "K = (np.arange(-3, 4, 1)*np.arange(-3, 4, 1)[:, np.newaxis])**2\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7f996-fa39-4ea3-a26f-b5a33001c219",
   "metadata": {},
   "source": [
    "b) Apply the perceptron update rule in dual representation (see below) to all five\n",
    "data points using the kernel from (a). Start with α = $\\vec{0}$, $b = 0$ and repeat the\n",
    "updating until all data points can be correctly classified:\n",
    "\n",
    "$$\n",
    "\\forall i : y_i \\left( \\sum_{j=1}^n \\alpha_j y_j \\langle x_1, x_2  \\rangle ^2 + b \\right) \\leq 0  \\Rightarrow \\alpha_i = \\alpha_i + 1; b = y_i (\\underset{j}{\\max} || x_j ||)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e22ea2d-f252-4360-a79f-6da53953a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "A = [-0.5, 1, 1]; B = [-1, -1.5, 0]; C = [-1.5, 1.5, 0]; D = [1.5, -0.5, 0]; E = [0.5, -0.5, 1]\n",
    "data_points = [A, B, C, D, E]\n",
    "\n",
    "# Create a flag\n",
    "miss_class = True \n",
    "\n",
    "# Repeat until we classify all points correctly  \n",
    "while miss_class:\n",
    "\n",
    "    # dummy \n",
    "    miss_class = False\n",
    "    pass\n",
    "\n",
    "    # Apply the perceptron training rule\n",
    "    \n",
    "    # Iterate over the training points \n",
    "    for data_point in data_points:\n",
    "        data_point[-1] * (alpha*data_point[0])\n",
    "    \n",
    "    # Check classification accuracy \n",
    "\n",
    "    # Update alpha (the Lagrange multiplier) \n",
    "\n",
    "    # Update bias \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b99fe-81e7-4b8f-931a-05ef08046b03",
   "metadata": {},
   "source": [
    "c) Classify the point X(-1;0) using the learned hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412fe5f8-b0a1-46b1-9a6a-4ea564991829",
   "metadata": {},
   "source": [
    "## Assignment 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eabc408-ee7b-4210-ba4c-1504c2e786c1",
   "metadata": {},
   "source": [
    "What is the main idea behind linear Support Vector Machines (SVMs)? Illustrate your\n",
    "explanation by drawing a figure. What equations are used in SVMs? How can a separating\n",
    "hyperplane with a maximal margin be found?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88011e67-a97c-47b5-8c96-b4de90d69365",
   "metadata": {},
   "source": [
    "The basic idea of SVMs is to find a hyperplane by virtue of implicitly mapping data to a space where they can be linearly separated using kernels. An important property of SVMs is that the determination of the model parameters corresponds to a convex optimisation problem, thus rendering any local solution a global optimum. \n",
    "\n",
    "The central equation of SVMs is centred around the decision function $f(x) = \\langle w, x \\rangle + b = \\sum_i \\alpha_i y_i \\langle x_i, x \\rangle+b$\n",
    "\n",
    "Below is a figure illustrating the implicit mapping to a new space with the associated kernel, newly rendering the problem linearly separable\n",
    "\n",
    "\n",
    "<img src=\"5_2_figure.png\" width=\"600\">\n",
    "\n",
    "\n",
    "In order to find the hyperplane with the maximal margin, we seek to minimise the size of the vector $w$ as per the figure below. Note the inconsistent notation with the bias term being subtracted rather than added, though the meaning isn't changed as the unary negation doesn't affect the linearity of the separation. \n",
    "\n",
    "<img src=\"5_3_figure.png\" width=\"400\">\n",
    "\n",
    "The minimisation itself is done in the context of constrained optimisation using Lagrange multipliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e8d2f-31a9-488f-bc59-7fafee0f352d",
   "metadata": {},
   "source": [
    "## Assignment 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad79f5-7e68-4a4e-a19d-8b3cd4be4ad7",
   "metadata": {},
   "source": [
    "How is the optimization problem of a Support Vector Machine modified to handle not\n",
    "linearly separable data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bda57-c188-4923-bab7-447228bd5f77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a0c4812-f38f-4cd6-9f8e-226dff930bf7",
   "metadata": {},
   "source": [
    "## Assignment 5.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b4215-26e6-4c42-abfa-a443d33b45c9",
   "metadata": {},
   "source": [
    "Present a kernel that was not described in the course. You should be able to describe how it\n",
    "is computed and in which scenarios it can be used. Look for articles describing this kernel.\n",
    "Examples of such kernels are string, tree or graph kernels or kernels for bioinformatics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002902a0-608e-4c4d-be8a-d3b0a8fb8938",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
